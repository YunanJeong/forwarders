[SERVICE]
    # Flush
    # =====
    # set an interval of seconds before to flush records to a destination
    flush        1

    # Daemon
    # ======
    # instruct Fluent Bit to run in foreground or background mode.
    # systemd로 제어시 비활성화
    daemon       Off          

    # Log_Level
    # =========
    # Set the verbosity level of the service, values can be:
    #
    # - error
    # - warning
    # - info
    # - debug
    # - trace
    #
    # by default 'info' is set, that means it includes 'error' and 'warning'.
    
    # 라이브에선 부하경감을 위해 최소한의 로그만 찍기
    log_level    debug                
    
    # default: none (=>stderr로 출력)
    log_file     /tmp/fluent-bit.log  


    # Parsers File
    # ============
    # specify an optional 'Parsers' configuration file
    parsers_file parsers.conf

    # Plugins File
    # ============
    # specify an optional 'Plugins' configuration file to load external plugins.
    plugins_file plugins.conf

    # HTTP Server
    # ===========
    # Enable/Disable the built-in HTTP Server for metrics
    http_server  Off
    http_listen  0.0.0.0
    http_port    2020

    # Storage
    # =======
    # Fluent Bit can use memory and filesystem buffering based mechanisms
    #
    # - https://docs.fluentbit.io/manual/administration/buffering-and-storage
    #
    # storage metrics
    # ---------------
    # publish storage pipeline metrics in '/api/v1/storage'. The metrics are
    # exported only if the 'http_server' option is enabled.
    #
    storage.metrics on

    # storage.path
    # ------------
    # absolute file system path to store filesystem data buffers (chunks).
    # 디스크 버퍼 최소설정: storage.path와 [INPUT]에서 storage.type filesystem 설정
    storage.path /tmp/storage  

    # storage.sync
    # ------------
    # configure the synchronization mode used to store the data into the
    # filesystem. It can take the values normal or full.
    # 단, 1건도 유실되면 안되는 경우 full로 설정. 부하 대폭증가 (CPU, 디스크IOPS, 디스크 쓰기 수) 
    # 보통 normal해도 문제 없음
    # 디스크 버퍼 사용시, 메모리에 있는걸 디스크 파일로 "확정(fsync)"하는 순간에 대한 문제
    storage.sync full   

    # storage.checksum
    # ----------------
    # enable the data integrity check when writing and reading data from the
    # filesystem. The storage layer uses the CRC32 algorithm.
    #
    # storage.checksum off

    # storage.backlog.mem_limit
    # -------------------------
    # if storage.path is set, Fluent Bit will look for data chunks that were
    # not delivered and are still in the storage layer, these are called
    # backlog data. This option configure a hint of maximum value of memory
    # to use when processing these records.
    # 디스크 버퍼에 있는 데이터를 다음 플러그인으로 전송하려면, 디스크 버퍼를 메모리로 읽어야 하는데 이 때 한도를 설정하는 것
    # 장기간 전송 실패 등으로 디스크 버퍼에 누적량(backlog)이 많을 때, 한번에 메모리를 과점유하지 않기 위해 쓰는 옵션
    storage.backlog.mem_limit 50M
    # 파일버퍼 활성화시 메모리버퍼의 크기 조정 (청크 당 2MB)
    storage.max_chunks_up 256


# 파일 읽기 # https://docs.fluentbit.io/manual/pipeline/inputs/tail
# 파일 개수 많을시
# # 리눅스: 서비스파일의 [SERVICE]하단에 LimitNOFILE=65536 (윈도는 기본값에서 이슈없음)
# # 윈도: 기본값 사용시 이슈없음
# # 쿠버네티스: k8s,docker 서비스 파일에서 [SERVICE]하단에 LimitNOFILE=65536. /etc/docker/daemon.json에도 설정필요할 수 있음. 이후 컨테이너 내부에서 ulimit -n으로 65536값 확인하여 적용여부 체크
[INPUT]
    Name tail                                 
    Path /var/log/*.log        
    
    # fluent 플랫폼 내부 메시지 라우팅을 위한 태그 
    Tag fltb.forwarding.tag
    
    # Parser 없이 그대로 포워딩할꺼임. 파일 로그라인의 json이 깨져도 그대로 전송 후 다운스트림 플랫폼에서 타당성체크 및 에러 라우팅
    # Parser json

    # 파일 처음부터 수집 시작 # 기존 DB파일 있을시 무시됨
    Read_From_Head true
    # 오프셋 저장용 내부 DB파일 활성화 및 경로 지정 → 재시작 시 위치 복구
    DB /tmp/fltb-tail.db

    # 로그출처파일경로를 메시지 필드에 추가 (필드명: file)
    Path_Key file

    # 한줄 로그 길이 제한 설정 (default: 32k) # 넘으면 짤려서 전송됨    
    Buffer_Max_Size 1MB

    # 파일버퍼 활성화
    storage.type filesystem

# fluentbit or fluentd로 보냄(Tag가 유지됨)
[OUTPUT]
    name forward
    match *
    Host localhost
    Port 24224
    # 통신 연결 멀티프로세싱 (속도 증가)
    Workers 2
    # at least once 및 전송속도를 위해 필요한 옵션
    Require_ack_response true

# 동일한 내용을 Kafka로도 보냄
[OUTPUT]
    Name        kafka
    Match       *
    Brokers     localhost:9095
    Topics      test-fluentbit
    Retry_Limit False
   
    # [INPUT]에서 데이터를 key-value형식으로 전달해주는데, 이를 최종적으로 어떻게 출력할지 결정.
    # 출력 포맷은 json, msgpack, csv, avro, protobuf 등 다양.
    # 이 예제에선 원본로그 내용을 json 검사하는게 아님!
    # tail에서 전달해준 "file"과 "log"를 key로하는 캡슐화된 데이터를 json으로 나타내겠다는 의미임
    Format      json

    # Kafka SASL 인증 설정
    # rdkafka.sasl.mechanisms    PLAIN
    # rdkafka.sasl.username      user1
    # rdkafka.sasl.password      11111
