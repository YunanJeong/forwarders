[SERVICE]
    # Flush
    # =====
    # set an interval of seconds before to flush records to a destination
    flush        1

    # Daemon
    # ======
    # instruct Fluent Bit to run in foreground or background mode.
    # systemd로 제어시 비활성화
    daemon       Off          

    # Log_Level
    # =========
    # Set the verbosity level of the service, values can be:
    #
    # - error
    # - warning
    # - info
    # - debug
    # - trace
    #
    # by default 'info' is set, that means it includes 'error' and 'warning'.
    
    # 라이브에선 부하경감을 위해 최소한의 로그만 찍기
    log_level    debug                
    
    # default: none (=>stderr로 출력)
    log_file     /tmp/fluent-bit.log  


    # Parsers File
    # ============
    # specify an optional 'Parsers' configuration file
    parsers_file parsers.conf

    # Plugins File
    # ============
    # specify an optional 'Plugins' configuration file to load external plugins.
    plugins_file plugins.conf

    # HTTP Server
    # ===========
    # Enable/Disable the built-in HTTP Server for metrics
    http_server  Off
    http_listen  0.0.0.0
    http_port    2020

    # Storage
    # =======
    # Fluent Bit can use memory and filesystem buffering based mechanisms
    #
    # - https://docs.fluentbit.io/manual/administration/buffering-and-storage
    #
    # storage metrics
    # ---------------
    # publish storage pipeline metrics in '/api/v1/storage'. The metrics are
    # exported only if the 'http_server' option is enabled.
    #
    storage.metrics on

    # storage.path
    # ------------
    # absolute file system path to store filesystem data buffers (chunks).
    # 디스크 버퍼 최소설정 storage.path와 각 input/output 플러그인에서 
    storage.path /tmp/storage  

    # storage.sync
    # ------------
    # configure the synchronization mode used to store the data into the
    # filesystem. It can take the values normal or full.
    # 단, 1건도 유실되면 안되는 경우 full로 설정. 부하 대폭증가 (CPU, 디스크IOPS, 디스크 쓰기 수) 
    # 보통 normal해도 문제 없음
    # 디스크 버퍼 사용시, 메모리에 있는걸 디스크 파일로 "확정(fsync)"하는 순간에 대한 문제
    storage.sync full   

    # storage.checksum
    # ----------------
    # enable the data integrity check when writing and reading data from the
    # filesystem. The storage layer uses the CRC32 algorithm.
    #
    # storage.checksum off

    # storage.backlog.mem_limit
    # -------------------------
    # if storage.path is set, Fluent Bit will look for data chunks that were
    # not delivered and are still in the storage layer, these are called
    # backlog data. This option configure a hint of maximum value of memory
    # to use when processing these records.
    # 디스크 버퍼에 있는 데이터를 다음 플러그인으로 전송하려면, 디스크 버퍼를 메모리로 읽어야 하는데 이 때 한도를 설정하는 것
    # 장기간 전송 실패 등으로 디스크 버퍼에 누적량(backlog)이 많을 때, 한번에 메모리를 과점유하지 않기 위해 쓰는 옵션
    # storage.backlog.mem_limit 5M  

# 파일 읽기 # https://docs.fluentbit.io/manual/pipeline/inputs/tail
# 파일 개수 많을시
# # 리눅스: 서비스파일의 [SERVICE]하단에 LimitNOFILE=65536 (윈도는 기본값에서 이슈없음)
# # 윈도: 기본값 사용시 이슈없음
# # 쿠버네티스: k8s,docker 서비스 파일에서 [SERVICE]하단에 LimitNOFILE=65536. /etc/docker/daemon.json에도 설정필요할 수 있음. 이후 컨테이너 내부에서 ulimit -n으로 65536값 확인하여 적용여부 체크

[INPUT]
    Name        tail
    Tag         tb.fluentd.alpha
    Path        /home/ubuntu/logsample/ds/ds_ibt_all/world*/GameLog/**/*.log
    Path_key    file
    DB          /tmp/fluent-bit-ds.fluentd.alpha.db
    Read_from_Head true
    Buffer_Max_Size 1m
    # storage.type filesystem

# fluentbit or fluentd로 보냄(Tag가 유지됨)
[OUTPUT]
    name forward
    match *
    Host localhost
    Port 24224
    Workers 2
    # at least once 및 전송속도를 위해 필요한 옵션
    Require_ack_response true


# [OUTPUT]
#     Name        kafka
#     Match       *
#     Brokers     localhost:9095
#     Topics      test-fluentbit
#     Format      json
#     Retry_Limit False
    # rdkafka.sasl.mechanisms    PLAIN
    # rdkafka.sasl.username      user1
    # rdkafka.sasl.password      11111